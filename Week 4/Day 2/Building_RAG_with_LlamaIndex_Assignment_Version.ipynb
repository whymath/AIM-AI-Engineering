{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5TTdyIoo3i7"
      },
      "source": [
        "# Creating a LlamaIndex RAG Pipeline with NL2SQL and Metadata Filtering!\n",
        "\n",
        "We'll be putting together a system for querying both qualitative and quantitative data using LlamaIndex.\n",
        "\n",
        "The acitvities will be broken down as follows:\n",
        "\n",
        "- ðŸ¤ Breakout Room #1\n",
        "  - Task 1: Load Dependencies\n",
        "  - Task 2: Set Env Variables and Set Up WandB Callback\n",
        "  - Task 3: Initialize Settings\n",
        "  - Task 4: Semantic RAG Pipeline with Metadata Filtering\n",
        "- ðŸ¤ Breakout Room #2\n",
        "  - Task 1: Quantitative RAG Pipeline with NL2SQL Tooling\n",
        "  - Task 2: Combined RAG Pipeline\n",
        "\n",
        "Before we get started, however, a quick note on terminology."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcvGuykZSV_8"
      },
      "source": [
        "### A note on terminology:\n",
        "\n",
        "You'll notice that there are quite a few similarities between LangChain and LlamaIndex. LlamaIndex can largely be thought of as an extension to LangChain, in some ways - but they moved some of the language around. Let's spend a few moments disambiguating the language.\n",
        "\n",
        "- `QueryEngine` -> `LCEL Chain`:\n",
        "  -  `QueryEngine` is just LlamaIndex's way of indicating something is an LLM \"chain\" on top of a retrieval system\n",
        "- `OpenAIAgent` vs. `Agent`:\n",
        "  - The two agents have the same fundamental pattern: Decide which of a list of tools to use to answer a user's query.\n",
        "  - `OpenAIAgent` (LlamaIndex's primary agent) does not need to rely on an agent excecutor due to the fact that it is leveraging OpenAI's [functional api](https://openai.com/blog/function-calling-and-other-api-updates) which allows the agent to interface \"directly\" with the tools instead of operating through an intermediary application process.\n",
        "\n",
        "There is, however, a much large terminological difference when it comes to discussing data.\n",
        "\n",
        "##### Nodes vs. Documents\n",
        "\n",
        "As you're aware of from the previous weeks assignments, there's an idea of `documents` in NLP which refers to text objects that exist within a corpus of documents.\n",
        "\n",
        "LlamaIndex takes this a step further and reclassifies `documents` as `nodes`. Confusingly, it refers to the `Source Document` as simply `Documents`.\n",
        "\n",
        "The `Document` -> `node` structure is, almost exactly, equivalent to the `Source Document` -> `Document` structure found in LangChain - but the new terminology comes with some clarity about different structure-indices.\n",
        "\n",
        "We won't be leveraging those structured indicies today, but we will be leveraging a \"benefit\" of the `node` structure that exists as a default in LlamaIndex, which is the ability to quickly filter nodes based on their metadata.\n",
        "\n",
        "![image](https://i.imgur.com/B1QDjs5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re0q6syjUVt0"
      },
      "source": [
        "# ðŸ¤ Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msvju70DSV_8"
      },
      "source": [
        "## BOILERPLATE\n",
        "\n",
        "This is only relevant when running the code in a Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7VF57GcmSV_9"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zQBPs6zSV_9"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhEbxl3nSV_9"
      },
      "source": [
        "Let's grab our core `llama-index` library, as well as OpenAI's Python SDK.\n",
        "\n",
        "We'll be leveraging OpenAI's suite of APIs to power our RAG pipelines today.\n",
        "\n",
        "> NOTE: You can safely ignore any pip errors that occur during the running of these cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3oyvtl2SV_9",
        "outputId": "3341b636-d1a3-4920-db19-ec06b9ee5f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (0.10.33)\n",
            "Requirement already satisfied: openai in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (1.24.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.2.3)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.12)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.32 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.10.33)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.9)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.16)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.5)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.19)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index) (0.1.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: certifi in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.6.5)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (2024.2.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.26.3)\n",
            "Requirement already satisfied: pandas in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (10.2.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.6.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.2.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: colorama in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: click in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index) (2024.4.28)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.2.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.32->llama-index) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U llama-index openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqTXRTrLPatl"
      },
      "source": [
        "We'll be collecting our semantic data from Wikipedia - and so will need the [Wikipedia Reader](https://github.com/run-llama/llama_index/tree/main/llama-index-integrations/readers/llama-index-readers-wikipedia)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9kXf7pPSV_-",
        "outputId": "7e106548-e671-4def-dd24-0b6fa0cf4324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (1.4.0)\n",
            "Requirement already satisfied: llama-index-readers-wikipedia in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (0.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-readers-wikipedia) (0.10.33)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.6.5)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.2.0)\n",
            "Requirement already satisfied: httpx in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.8.1)\n",
            "Requirement already satisfied: numpy in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.26.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.24.0)\n",
            "Requirement already satisfied: pandas in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (10.2.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.9.0)\n",
            "Requirement already satisfied: wrapt in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.4)\n",
            "Requirement already satisfied: pydantic>=1.10 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.7.1)\n",
            "Requirement already satisfied: anyio in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (4.3.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.5)\n",
            "Requirement already satisfied: sniffio in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.14.0)\n",
            "Requirement already satisfied: click in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (8.1.7)\n",
            "Requirement already satisfied: joblib in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.4.28)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.0.3)\n",
            "Requirement already satisfied: colorama in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-wikipedia) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U wikipedia llama-index-readers-wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq_rWHZEPrCO"
      },
      "source": [
        "Our vector database today will be powered by [QDrant](https://qdrant.tech/) and so we'll need that package as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMCA8HFGEPF_",
        "outputId": "ea5eec65-3fef-4539-eca6-d42cf4eacd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-vector-stores-qdrant in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (0.2.8)\n",
            "Requirement already satisfied: qdrant-client in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (1.9.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-vector-stores-qdrant) (1.62.2)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-vector-stores-qdrant) (0.10.33)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from qdrant-client) (1.62.2)\n",
            "Requirement already satisfied: httpx>=0.20.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.26 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from qdrant-client) (1.26.3)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from qdrant-client) (2.8.2)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from qdrant-client) (2.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from qdrant-client) (2.2.1)\n",
            "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (4.25.3)\n",
            "Requirement already satisfied: setuptools in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from grpcio-tools>=1.41.0->qdrant-client) (69.5.1)\n",
            "Requirement already satisfied: anyio in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\n",
            "Requirement already satisfied: certifi in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.5)\n",
            "Requirement already satisfied: idna in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7)\n",
            "Requirement already satisfied: sniffio in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.6.5)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.2.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.8.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.24.0)\n",
            "Requirement already satisfied: pandas in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (10.2.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.9.0)\n",
            "Requirement already satisfied: wrapt in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.16.0)\n",
            "Requirement already satisfied: pywin32>=226 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from portalocker<3.0.0,>=2.7.0->qdrant-client) (306)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic>=1.10.8->qdrant-client) (2.18.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.9.4)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: click in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (8.1.7)\n",
            "Requirement already satisfied: joblib in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.4.28)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.0.3)\n",
            "Requirement already satisfied: colorama in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.4.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U llama-index-vector-stores-qdrant qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNHDqna1P1NQ"
      },
      "source": [
        "Finally, we'll need to grab a few dependencies related to our quantitative data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrT8a3c0SV__",
        "outputId": "2474e86a-3310-463f-8ce1-6fe82a1dd4f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sqlalchemy in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (2.0.29)\n",
            "Requirement already satisfied: pandas in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from sqlalchemy) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from sqlalchemy) (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas) (1.26.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U sqlalchemy pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS3I4FUabE-g"
      },
      "source": [
        "We'll can use [Weights and Biases](https://docs.wandb.ai/guides/prompts) (WandB) as a visibility platform, as well as storing our index!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UcQpjG9Ovlk",
        "outputId": "3354d9eb-88b7-439d-c62e-ddf7d9ee30ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (0.16.6)\n",
            "Requirement already satisfied: llama-index-callbacks-wandb in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (5.9.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (2.0.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (69.5.1)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from wandb) (4.25.3)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-callbacks-wandb) (0.10.33)\n",
            "Requirement already satisfied: colorama in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
            "Requirement already satisfied: six>=1.4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (0.6.5)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2024.2.0)\n",
            "Requirement already satisfied: httpx in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (3.8.1)\n",
            "Requirement already satisfied: numpy in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.26.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.24.0)\n",
            "Requirement already satisfied: pandas in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2.2.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (10.2.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (4.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (0.9.0)\n",
            "Requirement already satisfied: wrapt in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.9.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2.7.1)\n",
            "Requirement already satisfied: anyio in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (4.3.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.0.5)\n",
            "Requirement already satisfied: sniffio in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (0.14.0)\n",
            "Requirement already satisfied: joblib in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2024.4.28)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (3.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in d:\\workspaces\\courses\\aimakerspace\\ai-engineering-cohort-2\\.venv\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.1->llama-index-callbacks-wandb) (2.18.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U wandb llama-index-callbacks-wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OHSwkDySV_-",
        "outputId": "71faaaea-a126-47ce-e86e-dbd8655314ed"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = getpass.getpass(\"WandB API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut8E447rQBjY"
      },
      "source": [
        "We'll also need to set a callback handler for WandB to ensure smooth operation of our traces!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "MoV2JINuSV_-",
        "outputId": "5ee85453-3505-48a6-efa1-98788ce63dc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Streaming LlamaIndex events to W&B at https://wandb.ai/ymath/llama-index-rag/runs/z7u88ysp\n",
            "wandb: `WandbCallbackHandler` is currently in beta.\n",
            "wandb: Please report any issues to https://github.com/wandb/wandb/issues with the tag `llamaindex`.\n"
          ]
        }
      ],
      "source": [
        "import llama_index\n",
        "from llama_index.core import set_global_handler\n",
        "\n",
        "set_global_handler(\"wandb\", run_args={\"project\": \"llama-index-rag\"})\n",
        "wandb_callback = llama_index.core.global_handler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibtguieHP6n1"
      },
      "source": [
        "## Task 2: Set Env Variables and Set Up WandB Callback\n",
        "\n",
        "Let's set our API keys for both OpenAI and WandB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IBgMTPTSV_9",
        "outputId": "74082918-7877-4153-f706-cc030b5f3b74"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQwigweOSV_-"
      },
      "source": [
        "### Task 3: Settings\n",
        "\n",
        "LlamaIndex lets us set global settings which we can use to influence the default behaviour of our components.\n",
        "\n",
        "Let's set our LLM and our Embedding Model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6KOy21KPSV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiOdw7EQSV_-"
      },
      "source": [
        "## `Index` Creation\n",
        "\n",
        "In order for us to perform RAG in the traditional sense - we need an `Index`.\n",
        "\n",
        "So what is an `Index`? Well - let's see how LlamaIndex defines it:\n",
        "\n",
        "> In LlamaIndex terms, an `Index` is a data structure composed of Document objects, designed to enable querying by an LLM. Your Index is designed to be complementary to your querying strategy.\n",
        "\n",
        "Okay, so we know that we have a boatload of Wikipedia content - and we know that we want to be able to query the `Index` and receive documents that are related to our query - so let's use an `Index` built on the idea of embedding-vectors.\n",
        "\n",
        "Introducing: `VectorStoreIndex`!\n",
        "\n",
        "Again, let's see how LlamaIndex defines this:\n",
        "\n",
        "> A `VectorStoreIndex` is by far the most frequent type of `Index` you'll encounter. The Vector Store Index takes your Documents and splits them up into Nodes. It then creates `vector` embeddings of the text of every node, ready to be queried by an LLM.\n",
        "\n",
        "Alright, that sounds awesome - let's make one!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDEtQQWnSV_-"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We're just going to be pulling information straight from Wikipedia using the built in `WikipediaReader`.\n",
        "\n",
        "> NOTE: Setting `auto_suggest=False` ensures we run into fewer auto-correct based errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OrzzrnYMSV_-"
      },
      "outputs": [],
      "source": [
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "\n",
        "movie_list = [\n",
        "    \"Dune (2021 film)\",\n",
        "    \"Dune: Part Two\",\n",
        "    \"The Lord of the Rings: The Fellowship of the Ring\",\n",
        "    \"The Lord of the Rings: The Two Towers\",\n",
        "]\n",
        "\n",
        "wiki_docs = WikipediaReader().load_data(pages=movie_list, auto_suggest=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6FRQ4hfSV_-"
      },
      "source": [
        "### Initializing our `VectorStoreIndex` with QDrant\n",
        "\n",
        "QDrant is a locally hostable and open-source vector database solution.\n",
        "\n",
        "It offers powerful features like metadata filtering out of the box, and will suit our needs well today!\n",
        "\n",
        "We'll start by creating our local `:memory:` client (in-memory and not meant for production use-cases) and our collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1ut96aSEVwY",
        "outputId": "126e308b-c9ba-4991-e26a-aea10f6243e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"movie_wikis\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa3mbrfGnkCk"
      },
      "source": [
        "Then we'll create our `VectorStore` and `StorageContext` which will allow us to create an empty `VectorStoreIndex` which we will be able to add nodes to later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ5xilm1SV_-",
        "outputId": "dd021273-3fe5-45e1-f1c3-b39698189759"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "vector_store = QdrantVectorStore(client=client, collection_name=\"movie_wikis\")\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    [],\n",
        "    storage_context=storage_context,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qtzVDelSV_-"
      },
      "source": [
        "### Node Construction\n",
        "\n",
        "Now we will loop through our documents and metadata and construct nodes.\n",
        "\n",
        "We'll make sure to explicitly associate our nodes with their respective movie so we can filter by the movie title in the upcoming cells.\n",
        "\n",
        "You might be thinking to yourself - wait, we never indicated which embedding model this should use - but remember"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP4INgSGSV_-",
        "outputId": "9cb343a0-989a-4768-946d-c891911d004b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "from llama_index.core.extractors import TitleExtractor\n",
        "\n",
        "pipeline = IngestionPipeline(transformations=[TokenTextSplitter()])\n",
        "\n",
        "for movie, wiki_doc in zip(movie_list, wiki_docs):\n",
        "  nodes = pipeline.run(documents=[wiki_doc])\n",
        "  for node in nodes:\n",
        "      node.metadata = {\"title\" : movie}\n",
        "  index.insert_nodes(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biVzC-I4UAmB"
      },
      "source": [
        "#### â“ Question #1:\n",
        "\n",
        "What `metadata` fields will the nodes in our index have?\n",
        "\n",
        "> You will need to write code to find this information\n",
        "\n",
        "#### ANSWER:\n",
        "\n",
        "We see that in this case, the metadata dictionary consists of 1 entry with the `title` key and the value containing the name of the movie (from whose Wikipedia page the data was taken)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mt1lhxEnUKxO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n",
            "node metadata:  {'title': 'The Lord of the Rings: The Two Towers'}\n"
          ]
        }
      ],
      "source": [
        "### YOUR CODE HERE\n",
        "for node in nodes:\n",
        "    print(\"node metadata: \", node.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfbon1BwSLFS"
      },
      "source": [
        "### Persisting and Loading Stored Index with Weights and Biases\n",
        "\n",
        "Now we can utilize a powerful feature of Weights and Biases - index and artifact versioning!\n",
        "\n",
        "We can persist our index to WandB to be used and loaded later!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJd00J3G48_",
        "outputId": "0a74079d-8776-4fa6-f03c-8ead3892d094"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Adding directory to artifact (d:\\Workspaces\\Courses\\AIMakerspace\\AI-Engineering-Cohort-2\\Week 4\\Day 2\\wandb\\run-20240430_014145-z7u88ysp\\files\\storage)... Done. 0.0s\n"
          ]
        }
      ],
      "source": [
        "wandb_callback.persist_index(index, index_name=\"movie-index-qdrant\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvpHLt8UShKa"
      },
      "source": [
        "Now we can load our index from WandB, which is a truly powerful tool!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDZLmqTDHDrZ",
        "outputId": "7b3dd1ec-2614-4017-d7a9-9295251ddce0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb:   4 of 4 files downloaded.  \n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "storage_context = wandb_callback.load_storage_context(\n",
        "    artifact_url=\"ymath/llama-index-rag/movie-index-qdrant:v0\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVVW70zyapx1"
      },
      "source": [
        "#### â“ Question #2:\n",
        "\n",
        "Provide a screenshot of your index version history as shown in WandB.\n",
        "\n",
        "You can find your screenshot by doing the following:\n",
        "\n",
        "![image](https://i.imgur.com/Y0AHkQI.png)\n",
        "\n",
        "#### ANSWER:\n",
        "\n",
        "The screenshot is available [here](https://drive.google.com/file/d/1aHFecoc8JisK8xUMVjb9AmCXlTnRKxHL/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCSHKnb0mIte"
      },
      "source": [
        "## Simple RAG - QueryEngine\n",
        "\n",
        "Now that we're created our `VectorStoreIndex`, powered by a QDrant VectorStore, we can wrap it in a simple `QueryEngine` using the `as_query_engine()` method - which will connect a few things together for us:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3ipb8j6dfLcO"
      },
      "outputs": [],
      "source": [
        "simple_rag = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgJZGr5FqAME"
      },
      "source": [
        "Before we test this out - let's see what information we can find out about from our new `QueryEngine`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-3v4ntaqFmd",
        "outputId": "15bd6ea0-f39f-480a-d715-0659dc8b058a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context information is below.\n",
            "---------------------\n",
            "{context_str}\n",
            "---------------------\n",
            "Given the context information and not prior knowledge, answer the query.\n",
            "Query: {query_str}\n",
            "Answer: \n",
            "\n",
            "~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "The original query is as follows: {query_str}\n",
            "We have provided an existing answer: {existing_answer}\n",
            "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
            "------------\n",
            "{context_msg}\n",
            "------------\n",
            "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
            "Refined Answer: \n",
            "\n",
            "~~~~~~~~~~~~~~~~~~\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for k, v in simple_rag.get_prompts().items():\n",
        "  print(v.get_template())\n",
        "  print(\"\\n~~~~~~~~~~~~~~~~~~\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1YoR45tnv8h"
      },
      "source": [
        "Let's see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgpQhKobfQ7y",
        "outputId": "494ef50d-b7a8-4800-8735-ac4adddf0926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = simple_rag.query(\"Who is the evil Wizard in the story?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "654d4vdfhnVq",
        "outputId": "ec3608c4-134a-4ac6-a654-9e65fa71ceb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The evil wizard in the story is Saruman the White.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8rRiijvpVoQ"
      },
      "source": [
        "That makes sense!\n",
        "\n",
        "Let's ask a question that's slightly more...ambiguous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m0H1tbLiqME",
        "outputId": "533148c8-05cf-44ef-ec52-28fe7539f5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = simple_rag.query(\"Who are the giant beings that roam across the world?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TEh4yjQzizeV",
        "outputId": "241b4b09-58c3-4d18-ca26-9813b38717e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The giant beings that roam across the world are sandworms.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOb6eh8_pnaX"
      },
      "source": [
        "We can check the source nodes to see which movies we retrieved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_qyApFDpPny",
        "outputId": "48041169-1504-4add-cdff-cdea4ffda118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Dune (2021 film)', 'The Lord of the Rings: The Fellowship of the Ring']\n"
          ]
        }
      ],
      "source": [
        "print([x.metadata[\"title\"] for x in response.source_nodes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBEXFmPapZpg"
      },
      "source": [
        "Okay, so in this case - we've gone with \"Sandworms \" from Dune.\n",
        "\n",
        "But there's also the Ents from Lord of the Rings, and it looks like we got documents from Lord of the Rings as well.\n",
        "\n",
        "Let's see if there's a way we can use the title metadata we added to filter the results we get!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUa5sHMsSV__"
      },
      "source": [
        "## Auto Retriever Functional Tool\n",
        "\n",
        "This tool will leverage OpenAI's functional endpoint to select the correct metadata filter and query the filtered index - only looking at nodes with the desired metadata.\n",
        "\n",
        "A simplified diagram: ![image](https://i.imgur.com/AICDPav.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2HQHY3pSV__"
      },
      "source": [
        "First, we need to create our `VectoreStoreInfo` object which will hold all the relevant metadata we need for each component (in this case title metadata).\n",
        "\n",
        "Notice that you need to include it in a text list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KoAYxbdsSV__"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.vector_stores.types import (\n",
        "    VectorStoreInfo,\n",
        "    MetadataInfo,\n",
        "    ExactMatchFilter,\n",
        "    MetadataFilters,\n",
        ")\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "from typing import List, Tuple, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "top_k = 3\n",
        "\n",
        "vector_store_info = VectorStoreInfo(\n",
        "    content_info=\"semantic information about movies\",\n",
        "    metadata_info=[MetadataInfo(\n",
        "        name=\"title\",\n",
        "        type=\"str\",\n",
        "        description='title of the movie, one of [\"Dune (2021 film)\", \"Dune: Part Two\", \"The Lord of the Rings: The Fellowship of the Ring\", \"The Lord of the Rings: The Two Towers\"]'\n",
        "        )]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEjK7jcsSV__"
      },
      "source": [
        "Now we'll create our base PyDantic object that we can use to ensure compatability with our application layer. This verifies that the response from the OpenAI endpoint conforms to this schema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "yixkwF8zSV__"
      },
      "outputs": [],
      "source": [
        "class AutoRetrieveModel(BaseModel):\n",
        "    query: str = Field(..., description=\"natural language query string\")\n",
        "    filter_key_list: List[str] = Field(\n",
        "        ..., description=\"List of metadata filter field names\"\n",
        "    )\n",
        "    filter_value_list: List[str] = Field(\n",
        "        ...,\n",
        "        description=(\n",
        "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep6ORS3FSV__"
      },
      "source": [
        "Now we can build our function that we will use to query the functional endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "y8sPThxlSV__"
      },
      "outputs": [],
      "source": [
        "def auto_retrieve_fn(\n",
        "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
        "):\n",
        "    \"\"\"Auto retrieval function.\n",
        "\n",
        "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
        "\n",
        "    \"\"\"\n",
        "    query = query or \"Query\"\n",
        "\n",
        "    exact_match_filters = [\n",
        "        ExactMatchFilter(key=k, value=v)\n",
        "        for k, v in zip(filter_key_list, filter_value_list)\n",
        "    ]\n",
        "    retriever = VectorIndexRetriever(\n",
        "        index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
        "    )\n",
        "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
        "\n",
        "    response = query_engine.query(query)\n",
        "    return str(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4BV6oISV__"
      },
      "source": [
        "Now we need to wrap our system in a tool in order to integrate it into the larger application.\n",
        "\n",
        "Source Code Here:\n",
        "- [`FunctionTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/function_tool.py#L21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "U4lS1NqeSV__"
      },
      "outputs": [],
      "source": [
        "description = f\"\"\"\\\n",
        "Use this tool to look up non-review based information about films.\n",
        "The vector database schema is given below:\n",
        "{vector_store_info.json()}\n",
        "\"\"\"\n",
        "\n",
        "auto_retrieve_tool = FunctionTool.from_defaults(\n",
        "    fn=auto_retrieve_fn,\n",
        "    name=\"semantic-film-info\",\n",
        "    description=description,\n",
        "    fn_schema=AutoRetrieveModel\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka_CDeOHbF-J"
      },
      "source": [
        "#### â“ Question #3:\n",
        "\n",
        "Is the text in the description of our `FunctionTool` important or not? Please explain your answer.\n",
        "\n",
        "#### ANSWER:\n",
        "\n",
        "The description is very important for the FunctionTool since it allows the LLM to determine when to use our custom `auto_retrieve_fn` function. It also contains the `vector_store_info` object's JSON output which gives a structured description of the vector store schema and the metadata filters available for use by the LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZblimmXVSV__"
      },
      "source": [
        "All that's left to do is attach the tool to an OpenAIAgent and let it rip!\n",
        "\n",
        "Source Code Here:\n",
        "- [`OpenAIAgent`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/agent/openai_agent.py#L361)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "W2hafCTxSV__"
      },
      "outputs": [],
      "source": [
        "from llama_index.agent.openai import OpenAIAgent\n",
        "\n",
        "agent = OpenAIAgent.from_tools(\n",
        "    tools=[auto_retrieve_tool],\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBJWDBK5SV__",
        "outputId": "278355ef-715c-4dcf-deb1-8eff22826a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Who starred in the 2021 film?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\":\"cast of Dune (2021 film)\",\"filter_key_list\":[\"title\"],\"filter_value_list\":[\"Dune (2021 film)\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The cast of Dune (2021 film) includes TimothÃ©e Chalamet as Paul Atreides, Rebecca Ferguson as Lady Jessica, Oscar Isaac as Duke Leto Atreides, Josh Brolin as Gurney Halleck, Stellan SkarsgÃ¥rd as Baron Vladimir Harkonnen, Dave Bautista as Glossu Rabban, Sharon Duncan-Brewster as Dr. Liet Kynes, Stephen McKinley Henderson as Thufir Hawat, Zendaya as Chani, Chang Chen as Dr. Wellington Yueh, Charlotte Rampling as Reverend Mother Mohiam, Jason Momoa as Duncan Idaho, Javier Bardem as Stilgar, David Dastmalchian as Piter De Vries, Babs Olusanmokun as Jamis, Golda Rosheuvel as Shadout Mapes, and Roger Yuan as Lieutenant Lanville.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 2021 film \"Dune\" stars TimothÃ©e Chalamet, Rebecca Ferguson, Oscar Isaac, Josh Brolin, Stellan SkarsgÃ¥rd, Dave Bautista, Sharon Duncan-Brewster, Stephen McKinley Henderson, Zendaya, Chang Chen, Charlotte Rampling, Jason Momoa, Javier Bardem, David Dastmalchian, Babs Olusanmokun, Golda Rosheuvel, and Roger Yuan.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Who starred in the 2021 film?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZzs2PyDuJGX",
        "outputId": "1b195ad9-c3ed-4901-aac8-3be932d42222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Who are those giant guys from Lord of the Rings that roam around the forest?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\":\"characters from The Lord of the Rings: The Two Towers\",\"filter_key_list\":[\"title\"],\"filter_value_list\":[\"The Lord of the Rings: The Two Towers\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: Frodo Baggins, Gandalf the White, Aragorn, Samwise Gamgee, Gollum, Peregrin Took, Meriadoc Brandybuck, Gimli, Legolas, ThÃ©oden, Saruman the White, Elrond, Ã‰owyn, Faramir, GrÃ­ma Wormtongue, Ã‰omer, Arwen, Galadriel, Boromir, Haldir, HÃ¡ma, Gamling, Madril, Ugluk, Denethor.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The giant guys from \"The Lord of the Rings: The Two Towers\" are likely the Ents, also known as Treebeard and the Ents of Fangorn Forest. They are ancient tree-like creatures who roam the forest and play a significant role in the story.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"Who are those giant guys from Lord of the Rings that roam around the forest?\")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_GqxFCVbKch"
      },
      "source": [
        "# ðŸ¤ Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJcJL7VXSV__"
      },
      "source": [
        "## Quantitative RAG Pipeline with NL2SQL Tooling\n",
        "\n",
        "We'll walk through the steps of creating a natural language to SQL system in the following section.\n",
        "\n",
        "> NOTICE: This does not have parsing on the inputs or intermediary calls to ensure that users are using safe SQL queries. Use this with caution in a production environment without adding specific guardrails from either side of the application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsVcM0-4SV__"
      },
      "source": [
        "The next few steps should be largely straightforward, we'll want to:\n",
        "\n",
        "1. Read in our `.csv` files into `pd.DataFrame` objects\n",
        "2. Create an in-memory `sqlite` powered `sqlalchemy` engine\n",
        "3. Cast our `pd.DataFrame` objects to the SQL engine\n",
        "4. Create an `SQLDatabase` object through LlamaIndex\n",
        "5. Use that to create a `QueryEngineTool` that we can interact with through the `NLSQLTableQueryEngine`!\n",
        "\n",
        "If you get stuck, please consult the documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwWOygTqlNBh",
        "outputId": "ac7633a8-3e17-42e5-8c60-0f29b1927ceb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
            "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
            "--2024-04-30 01:50:13--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune1.csv\n",
            "Resolving raw.githubusercontent.com... 185.199.110.133, 185.199.109.133, 185.199.108.133, ..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Connecting to raw.githubusercontent.com|185.199.110.133|:443... connected.\n",
            "OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol\n",
            "Unable to establish SSL connection.\n"
          ]
        }
      ],
      "source": [
        "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD_9LPL9lTlG",
        "outputId": "664f4689-8f10-4624-e01d-fb15cf381a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-25 22:44:33--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 111843 (109K) [text/plain]\n",
            "Saving to: â€˜dune2.csvâ€™\n",
            "\n",
            "dune2.csv           100%[===================>] 109.22K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2024-04-25 22:44:34 (33.8 MB/s) - â€˜dune2.csvâ€™ saved [111843/111843]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/dune2.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWFWvEdY1inS",
        "outputId": "f827c8d9-82e4-425b-9b04-eca7f8225da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-25 22:44:34--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_fotr.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172855 (169K) [text/plain]\n",
            "Saving to: â€˜lotr_fotr.csvâ€™\n",
            "\n",
            "\rlotr_fotr.csv         0%[                    ]       0  --.-KB/s               \rlotr_fotr.csv       100%[===================>] 168.80K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-25 22:44:34 (38.0 MB/s) - â€˜lotr_fotr.csvâ€™ saved [172855/172855]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_fotr.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nto_jNmN1n-G",
        "outputId": "ee1b2970-2bcf-48f9-e0fd-1eae06f7d162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-25 22:44:34--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_tt.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114598 (112K) [text/plain]\n",
            "Saving to: â€˜lotr_tt.csvâ€™\n",
            "\n",
            "\rlotr_tt.csv           0%[                    ]       0  --.-KB/s               \rlotr_tt.csv         100%[===================>] 111.91K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-04-25 22:44:34 (26.8 MB/s) - â€˜lotr_tt.csvâ€™ saved [114598/114598]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/lotr_tt.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PUg-ZuTSWAC"
      },
      "source": [
        "#### Read `.csv` Into Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "52Hd8PM4SWAC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# dune1 = pd.read_csv(\"./dune1.csv\")\n",
        "# dune2 = pd.read_csv(\"./dune2.csv\")\n",
        "# lotr_fotr = pd.read_csv(\"./lotr_fotr.csv\")\n",
        "# lotr_tt = pd.read_csv(\"./lotr_tt.csv\")\n",
        "dune1 = pd.read_csv(\"./../../../DataRepository/dune1.csv\")\n",
        "dune2 = pd.read_csv(\"./../../../DataRepository/dune2.csv\")\n",
        "lotr_fotr = pd.read_csv(\"./../../../DataRepository/lotr_fotr.csv\")\n",
        "lotr_tt = pd.read_csv(\"./../../../DataRepository/lotr_tt.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPTNyqmpSWAC"
      },
      "source": [
        "#### Create SQLAlchemy engine with SQLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "4lfuPKYBSWAC"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"sqlite+pysqlite:///:memory:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJiYiSuHSWAC"
      },
      "source": [
        "#### Convert `pd.DataFrame` to SQL tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-96asUHSWAC",
        "outputId": "d0ac06f5-b828-4347-e6dc-46f6c9811f85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dune1.to_sql(\n",
        "  \"Dune (2021 film)\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwOi1RE1SWAC",
        "outputId": "c1517e82-1522-4d9e-cd16-bf988b4664c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dune2.to_sql(\n",
        "  \"Dune: Part Two\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R6FTIki4Q51",
        "outputId": "7d69a127-d1a3-49ae-e8b5-61a876b64d94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "250"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lotr_fotr.to_sql(\n",
        "  \"The Lord of the Rings: The Fellowship of the Ring\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CiP8dwV4SFZ",
        "outputId": "1f25f185-ed2c-4e44-be04-583333c20863"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lotr_tt.to_sql(\n",
        "  \"The Lord of the Rings: The Two Towers\",\n",
        "  engine\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pibA9qT7SWAC"
      },
      "source": [
        "#### Construct a `SQLDatabase` index\n",
        "\n",
        "Source Code Here:\n",
        "- [`SQLDatabase`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/langchain_helpers/sql_wrapper.py#L9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "yeDYpR1LSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SQLDatabase\n",
        "\n",
        "sql_database = SQLDatabase(\n",
        "    engine=engine,\n",
        "    include_tables=movie_list\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7VfZBenSWAD"
      },
      "source": [
        "#### Create the NLSQLTableQueryEngine interface for all added SQL tables\n",
        "\n",
        "Source Code Here:\n",
        "- [`NLSQLTableQueryEngine`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/indices/struct_store/sql_query.py#L75C1-L75C1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zQWSdMtrSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
        "\n",
        "sql_query_engine = NLSQLTableQueryEngine(\n",
        "    sql_database=sql_database,\n",
        "    tables=movie_list,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu8WfwuTSWAD"
      },
      "source": [
        "#### Wrap It All Up in a `QueryEngineTool`\n",
        "\n",
        "You'll want to ensure you have a descriptive...description!\n",
        "\n",
        "This is what will help the LLM decide which table to use when querying!\n",
        "\n",
        "Sorce Code Here:\n",
        "\n",
        "- [`QueryEngineTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/query_engine.py#L13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sjbHnA1bQBG"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1:\n",
        "\n",
        "Please write a Natural Language Description for the tables that we are using today.\n",
        "\n",
        "Here is an example:\n",
        "\n",
        "```\n",
        "This tool should be used to answer any and all review related inquiries by translating a natural language query into a SQL query with access to tables:\n",
        "'Dune (2021 film)' - containing info. about the first movie in the Dune series,\n",
        "'Dune: Part Two'- containing info. about about the second movie in the Dune series,\n",
        "'The Lord of the Rings: The Fellowship of the Ring' - containing info. about the first movie in the Lord of the Ring series,\n",
        "'The Lord of the Rings: The Two Towers' - containing info. the second movie in the Lord of the Ring series,\n",
        "```\n",
        "\n",
        "#### ANSWER:\n",
        "\n",
        "Natural language descriptions for the SQL tables can be as below:\n",
        "```\n",
        "This tool should be used to answer any review related inquiries by translating a natural language query into a SQL query with access to the following tables:\n",
        "'Dune (2021 film)' - This table contains information about the first movie in the Dune movie series,\n",
        "'Dune: Part Two'- This table contains information about the second movie in the Dune movie series,\n",
        "'The Lord of the Rings: The Fellowship of the Ring' - This table contains information about the first movie in the Lord of the Rings movie series,\n",
        "'The Lord of the Rings: The Two Towers' - This table contains information about the second movie in the Lord of the Rings movie series,\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4n567cXVVCtX"
      },
      "outputs": [],
      "source": [
        "DESCRIPTION = \"\"\"\n",
        "This tool should be used to answer any and all review related inquiries by translating a natural language query into a SQL query with access to tables:\n",
        "'Dune (2021 film)' - containing info. about the first movie in the Dune series,\n",
        "'Dune: Part Two'- containing info. about about the second movie in the Dune series,\n",
        "'The Lord of the Rings: The Fellowship of the Ring' - containing info. about the first movie in the Lord of the Ring series,\n",
        "'The Lord of the Rings: The Two Towers' - containing info. the second movie in the Lord of the Ring series,\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "y-mmcBbLSWAD"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.tools.query_engine import QueryEngineTool\n",
        "\n",
        "sql_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=sql_query_engine,\n",
        "    name=\"sql-query\",\n",
        "    description=DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "feOrlq4XSWAD"
      },
      "outputs": [],
      "source": [
        "agent = OpenAIAgent.from_tools(\n",
        "    tools=[sql_tool],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT4G6stBSWAD",
        "outputId": "71ce1dad-d853-40a3-b223-4c84268f1042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What is the average rating of the 2nd Lord of the Rings movie?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\":\"average rating of 'The Lord of the Rings: The Two Towers'\"}\n",
            "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The average rating of 'The Lord of the Rings: The Two Towers' is 9.18 out of 10.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What is the average rating of the 2nd Lord of the Rings movie?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhsoxOpkSWAD",
        "outputId": "5309b4dc-6259-42f9-d1de-9ba6cc11325b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average rating of the 2nd Lord of the Rings movie, \"The Lord of the Rings: The Two Towers,\" is 9.18 out of 10.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FiAS6sF7DoJ",
        "outputId": "58798450-508a-43fb-b869-d6ded1d16427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What movie series has better reviews, Lord of the Rings or Dune?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"average rating of 'The Lord of the Rings: The Fellowship of the Ring'\"}\n",
            "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The average rating of 'The Lord of the Rings: The Fellowship of the Ring' is approximately 9.87 out of 10.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\": \"average rating of 'Dune (2021 film)'\"}\n",
            "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The average rating for the movie \"Dune (2021 film)\" is 8.34 out of 10.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = agent.chat(\"What movie series has better reviews, Lord of the Rings or Dune?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxDA2Gjm7dDZ",
        "outputId": "277ef033-0fea-486c-be00-1f1d24bc5cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average rating of \"The Lord of the Rings: The Fellowship of the Ring\" is approximately 9.87 out of 10, while the average rating for the movie \"Dune (2021 film)\" is 8.34 out of 10. Therefore, the Lord of the Rings series has better reviews compared to the Dune series.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2LOixbcSWAD"
      },
      "source": [
        "### Task 2: Combined RAG Pipeline\n",
        "\n",
        "Now, we can simply add our tools into the `OpenAIAgent`, and off we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "uxFHM2l2SWAD"
      },
      "outputs": [],
      "source": [
        "combined_tool_agent = OpenAIAgent.from_tools(\n",
        "    tools=[auto_retrieve_tool, sql_tool],\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYVHuBf9SWAD",
        "outputId": "80bb8608-a4ea-43ca-d312-d941cb1c7ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Which movie is about a ring, and what is the average rating of the movie?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\":\"movie about a ring\",\"filter_key_list\":[\"title\"],\"filter_value_list\":[\"The Lord of the Rings: The Fellowship of the Ring\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The Lord of the Rings: The Fellowship of the Ring\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: sql-query with args: {\"input\":\"average rating of The Lord of the Rings: The Fellowship of the Ring\"}\n",
            "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "> Table desc str: Table 'Dune (2021 film)' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'Dune: Part Two' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Fellowship of the Ring' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "\n",
            "Table 'The Lord of the Rings: The Two Towers' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The average rating of The Lord of the Rings: The Fellowship of the Ring is approximately 9.87 out of 10.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = combined_tool_agent.chat(\"Which movie is about a ring, and what is the average rating of the movie?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0w0VbomSWAD",
        "outputId": "da523a93-4cfd-4e28-ac5a-95f637d730dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The movie about a ring is \"The Lord of the Rings: The Fellowship of the Ring,\" and it has an average rating of approximately 9.87 out of 10.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJvN-vtJSWAD",
        "outputId": "bb30f3ac-e495-48cc-c892-6f762d962c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: What worlds do the LoTR, and Dune movies take place in?\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"worlds of LoTR\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"The Lord of the Rings: The Fellowship of the Ring\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The worlds of \"The Lord of the Rings\" include Middle-earth, which is the primary setting for the story. Within Middle-earth, there are various regions such as Rivendell, LothlÃ³rien, Isengard, Mordor, and the Shire. These regions are inhabited by different races including Elves, Men, Dwarves, Hobbits, and Orcs. Middle-earth is a vast and diverse world filled with rich history, cultures, and landscapes that play a significant role in the events of the story.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"worlds of Dune\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"Dune (2021 film)\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: The worlds of Dune include Caladan, Arrakis, and Giedi Prime, each playing a significant role in the storyline of the film. These planets are diverse in their environments and cultures, contributing to the rich and intricate universe depicted in the movie.\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = combined_tool_agent.chat(\"What worlds do the LoTR, and Dune movies take place in?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F74wGv6NSWAD",
        "outputId": "05b9020b-9e8f-41a5-b1ee-602b6668691a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- The \"Lord of the Rings\" movies take place in the world of Middle-earth, which includes regions like Rivendell, LothlÃ³rien, Isengard, Mordor, and the Shire. This world is inhabited by various races such as Elves, Men, Dwarves, Hobbits, and Orcs, and it is known for its rich history, cultures, and landscapes.\n",
            "\n",
            "- The \"Dune\" movie is set in worlds like Caladan, Arrakis, and Giedi Prime. Each of these planets plays a significant role in the storyline of the film, offering diverse environments and cultures that contribute to the intricate universe depicted in the movie.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvat4hmkvn3N",
        "outputId": "dd4f7f35-5f8e-4b9b-ac71-cdf73fdb6845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added user message to memory: Which of the following movie series is considered the 'best': Dune, or Lord of the Rings? Base your answer on both reviews, and non-review information.\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"best movie series between Dune and Lord of the Rings\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"Dune (2021 film)\", \"The Lord of the Rings: The Fellowship of the Ring\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: Dune is considered to be a successful film adaptation that was well received by both critics and audiences, with praise for its direction, screenplay, production values, and faithfulness to the source material. The film was a box office success and won several awards. On the other hand, The Lord of the Rings film series is also highly regarded for maintaining key characters and plots while managing limited running time, resulting in critical and commercial success. Both film series have their own strengths and have been well-received in their own right.\n",
            "========================\n",
            "\n",
            "=== Calling Function ===\n",
            "Calling function: semantic-film-info with args: {\"query\": \"best movie series between Dune and Lord of the Rings\", \"filter_key_list\": [\"title\"], \"filter_value_list\": [\"Dune: Part Two\", \"The Lord of the Rings: The Two Towers\"]}\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "Got output: Dune\n",
            "========================\n",
            "\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Logged trace tree to W&B.\n"
          ]
        }
      ],
      "source": [
        "response = combined_tool_agent.chat(\"Which of the following movie series is considered the 'best': Dune, or Lord of the Rings? Base your answer on both reviews, and non-review information.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEOpeuAovtZM",
        "outputId": "441769b0-ead5-4eda-efa1-dd81d18e8534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on reviews and non-review information, both the \"Dune\" movie series and \"The Lord of the Rings\" movie series are considered to be exceptional in their own right:\n",
            "\n",
            "- **Dune**: The \"Dune\" movie is a successful film adaptation that received praise for its direction, screenplay, production values, and faithfulness to the source material. It was well-received by both critics and audiences, achieving commercial success and winning several awards.\n",
            "\n",
            "- **The Lord of the Rings**: The \"Lord of the Rings\" film series is highly regarded for maintaining key characters and plots while effectively managing limited running time. It has garnered critical acclaim and commercial success for its storytelling and cinematic achievements.\n",
            "\n",
            "Both movie series have their strengths and have been well-received, making it challenging to definitively declare one as the \"best\" over the other. Each series has its unique appeal and has resonated with audiences and critics alike.\n"
          ]
        }
      ],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1qaiDJYb1_v"
      },
      "source": [
        "#### â“ Question #4:\n",
        "\n",
        "How can you verify which tool was used for which query?\n",
        "\n",
        "#### ANSWER:\n",
        "\n",
        "In the trace of the OpenAI calls, we have logs in the following format:\n",
        "```\n",
        "=== Calling Function ===\n",
        "Calling function: <function-name> with args:\n",
        "```\n",
        "\n",
        "The presence of these logs indicate that the agent is performing function calling, and the `<function-name>` value indicates the one being called.\n",
        "\n",
        "In the case of our `combined_tool_agent`, we can see that the `sql-query` function was called for the \"Which movie is about a ring, and what is the average rating of the movie?\" query, while the `semantic-film-info` function was called for all three queies.\n",
        "\n",
        "Alternatively, we can also use the values of the `tool_name` keys inside the corresponding `response` object to understand which tools are being used (including function calling) for each query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "D3ELqzOvSWAD"
      },
      "outputs": [],
      "source": [
        "wandb_callback.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
